# Artificial Neural Networks - Studies

This project is an implementation of various neural network models, including Hopfield Networks, Boltzmann Machine, Markov Assumption and Markov Chain, Feed Forward, and Multilayer Perceptron (MLP). These models are widely used in the field of machine learning and artificial intelligence for tasks such as image recognition, speech recognition, and natural language processing.The application part is MLP and the other parts are theoretical information in Latex format.

## Hopfield Networks
Hopfield Networks are a type of recurrent neural network that can store and retrieve patterns from memory. They are used for tasks such as associative memory, pattern recognition, and image reconstruction. In this project, we implement a Python-based version of Hopfield Networks, complete with training and testing functionalities.

## Boltzmann Machine
Boltzmann Machine is a type of stochastic recurrent neural network that is used for modeling probabilistic distributions. It consists of a network of binary units that are connected in a symmetric fashion, and it uses a Markov Chain Monte Carlo (MCMC) approach for training. In this project, we provide an implementation of Boltzmann Machine in Python, along with training and sampling functionalities.

## Markov Assumption and Markov Chain
Markov Assumption is a statistical assumption that states that the future state of a system depends only on its current state and not on its past states. Markov Chain is a mathematical model that describes the transition probabilities between different states of a system that satisfies the Markov Assumption. In this project, we implement a Markov Chain in Python, and we use it as the basis for training and testing various neural network models.

## Feed Forward
Feed Forward neural networks are the most basic type of neural networks, where information flows in only one direction, from input to output. They consist of layers of interconnected nodes, or neurons, with each neuron processing the input and passing it to the next layer. In this project, we implement a Feed Forward neural network in Python, complete with training and testing functionalities.

## Multilayer Perceptron (MLP)
Multilayer Perceptron (MLP) is a type of Feed Forward neural network that consists of multiple layers of interconnected neurons, with each layer having its own set of weights and biases. MLP is a popular choice for tasks such as image classification, speech recognition, and natural language processing. In this project, we provide an implementation of MLP in Python, along with training and testing functionalities.

Overall, this project aims to provide a comprehensive implementation of various neural network models, along with training and testing functionalities, in Python. These models can be used for a wide range of applications in machine learning and artificial intelligence, and can serve as a valuable resource for researchers and practitioners in the field.


## Dataset
The dataset used in this project is obtained from Kaggle, a popular platform for data science competitions. Link is here: [https://www.kaggle.com/datasets/unmoved/cure-the-princess](https://www.kaggle.com/datasets/unmoved/cure-the-princess)

## Installation

Use the package manager [pip](https://pip.pypa.io/en/stable/) to install foobar.

```bash
pip install torcheval
pip install torchmetrics
```

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

[MIT](https://choosealicense.com/licenses/mit/)
